{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora dataset: #classes = 7 , #features = 1433 , #nodes = 2708 , #edges = 5278\n",
      "Feature set shapes (train, valid, test): (140, 1433) (500, 1433) (1000, 1433)\n",
      "Labels shapes (train, valid, test): (140, 7) (500, 7) (1000, 7)\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Semi-Supervised Classification of Graph Nodes using Exponential Decay\n",
    "# L42: Assessment 2\n",
    "# Jan Ondras (jo356), Trinity College\n",
    "######################################################################\n",
    "# Baseline MLP training and validation, Cora dataset\n",
    "#############################################################################################################\n",
    "# Load data \n",
    "#############################################################################################################\n",
    "\n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from gcn.utils import *\n",
    "\n",
    "dataset_type = 'cora'\n",
    "\n",
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(dataset_type)\n",
    "\n",
    "if dataset_type == 'cora':\n",
    "    N_classes = 7\n",
    "    N_features = 1433\n",
    "    N_nodes = 2708\n",
    "    N_edges = 5278 #5429 - incorrect in paper !\n",
    "    if N_classes != y_train.shape[1] or N_features != features.shape[1] or N_nodes != features.shape[0] or N_edges != np.sum(adj.todense())/2:\n",
    "        raise ValueError(\"Dataset dimensions differ from expected!\")\n",
    "else:\n",
    "    raise ValueError(\"Dataset not supported!\")\n",
    "print dataset_type, \"dataset:\", \"#classes =\", N_classes, \", #features =\", N_features, \", #nodes =\", N_nodes, \", #edges =\", N_edges\n",
    "\n",
    "X_train = features[train_mask].toarray()\n",
    "X_val = features[val_mask].toarray()\n",
    "X_test = features[test_mask].toarray()\n",
    "y_train = y_train[train_mask]\n",
    "y_val = y_val[val_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "print \"Feature set shapes (train, valid, test):\", X_train.shape, X_val.shape, X_test.shape\n",
    "print \"Labels shapes (train, valid, test):\", y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph of the network\n",
    "G = nx.from_scipy_sparse_matrix(adj)\n",
    "# pos = nx.spring_layout(G)\n",
    "plt.figure(figsize=(15,15))\n",
    "nx.draw(G, node_size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation over  150 = 10 x 15 parameter settings\n",
      "Time taken:  14.9907910824 0.249849418799\n",
      "Time taken:  16.9219071865 0.28203531901\n",
      "Time taken:  12.910943985 0.215182880561\n",
      "Time taken:  13.5918500423 0.226533651352\n",
      "Time taken:  13.7651000023 0.229419668516\n",
      "Time taken:  15.1787371635 0.252981499831\n",
      "Time taken:  14.5438978672 0.24239881436\n",
      "Time taken:  14.503319025 0.241722500324\n",
      "Time taken:  14.9355580807 0.248926432927\n",
      "Time taken:  15.2085719109 0.253476715088\n",
      "Time taken:  14.7952589989 0.246590264638\n",
      "Time taken:  15.8221640587 0.263703465462\n",
      "Time taken:  16.4285390377 0.273809631666\n",
      "Time taken:  15.6358048916 0.260597248872\n",
      "Time taken:  16.9731218815 0.28288586537\n",
      "Time taken:  17.7909829617 0.296520316601\n",
      "Time taken:  21.5377390385 0.358964852492\n",
      "Time taken:  17.8638181686 0.297732019424\n",
      "Time taken:  18.6987950802 0.311650983493\n",
      "Time taken:  19.3455328941 0.322426116467\n",
      "Time taken:  19.4145600796 0.323579068979\n",
      "Time taken:  20.3973379135 0.339958449205\n",
      "Time taken:  21.9887621403 0.366480032603\n",
      "Time taken:  21.2651059628 0.354419199626\n",
      "Time taken:  24.1705551147 0.402844401201\n",
      "Time taken:  22.2965171337 0.371609318256\n",
      "Time taken:  22.6137599945 0.376896635691\n",
      "Time taken:  25.1833541393 0.419726467133\n",
      "Time taken:  21.7253541946 0.362089836597\n",
      "Time taken:  24.1301851273 0.402171250184\n",
      "Time taken:  20.3714749813 0.339525282383\n",
      "Time taken:  26.0908169746 0.434847664833\n",
      "Time taken:  21.7370481491 0.362284700076\n",
      "Time taken:  21.6208732128 0.360348419348\n",
      "Time taken:  24.1070799828 0.401805035273\n",
      "Time taken:  27.1407830715 0.452347036203\n",
      "Time taken:  25.5099790096 0.42516686519\n",
      "Time taken:  27.8029801846 0.463387835026\n",
      "Time taken:  26.1462688446 0.435771930218\n",
      "Time taken:  27.6665170193 0.461111617088\n",
      "Time taken:  33.0392849445 0.550655333201\n",
      "Time taken:  34.6430988312 0.577388699849\n",
      "Time taken:  31.8258821964 0.530435585976\n",
      "Time taken:  31.6492409706 0.527487866084\n",
      "Time taken:  31.1126849651 0.518545265992\n",
      "Time taken:  26.8556399345 0.447599081198\n",
      "Time taken:  24.5971388817 0.409952934583\n",
      "Time taken:  25.1495580673 0.419159865379\n",
      "Time taken:  28.5919361115 0.476536568006\n",
      "Time taken:  34.9166719913 0.581945097446\n",
      "Time taken:  31.8120961189 0.530204832554\n",
      "Time taken:  32.4083127975 0.540139230092\n",
      "Time taken:  31.1181960106 0.518637180328\n",
      "Time taken:  39.9371049404 0.665619198481\n",
      "Time taken:  36.6059539318 0.610103766123\n",
      "Time taken:  37.1762862206 0.619606101513\n",
      "Time taken:  50.3839709759 0.839757231871\n",
      "Time taken:  43.518807888 0.725314084689\n",
      "Time taken:  45.0994129181 0.751657414436\n",
      "Time taken:  49.0639770031 0.817733597755\n",
      "Time taken:  29.5255179405 0.492092665037\n",
      "Time taken:  32.7995660305 0.546659982204\n",
      "Time taken:  35.4919159412 0.591534614563\n",
      "Time taken:  36.7888479233 0.613151264191\n",
      "Time taken:  37.666216135 0.62777081728\n",
      "Time taken:  38.3563830853 0.63927393357\n",
      "Time taken:  38.997456789 0.649958280722\n",
      "Time taken:  43.6983520985 0.728309269746\n",
      "Time taken:  46.5300879478 0.775502049923\n",
      "Time taken:  47.3807361126 0.78967966636\n",
      "Time taken:  50.2494621277 0.837491734823\n",
      "Time taken:  50.1799008846 0.836332265536\n",
      "Time taken:  49.9504158497 0.832510733604\n",
      "Time taken:  45.5322539806 0.758871618907\n",
      "Time taken:  45.642385006 0.760706984997\n",
      "Time taken:  32.170568943 0.536180500189\n",
      "Time taken:  35.5475120544 0.592460266749\n",
      "Time taken:  31.9096021652 0.531827135881\n",
      "Time taken:  32.4089529514 0.540152533849\n",
      "Time taken:  38.8363788128 0.647275380294\n",
      "Time taken:  37.8633859158 0.631056980292\n",
      "Time taken:  36.0684859753 0.601142052809\n",
      "Time taken:  38.0685348511 0.634478465716\n",
      "Time taken:  42.9490909576 0.715818715096\n",
      "Time taken:  38.4623091221 0.641041199366\n",
      "Time taken:  44.2311599255 0.737186582883\n",
      "Time taken:  42.5575330257 0.709294716517\n",
      "Time taken:  49.9114120007 0.831857430935\n",
      "Time taken:  44.8770670891 0.747951833407\n",
      "Time taken:  45.1901421547 0.753169667721\n",
      "Time taken:  31.6307890415 0.527180480957\n",
      "Time taken:  41.2643408775 0.687739531199\n",
      "Time taken:  36.3421180248 0.605705165863\n",
      "Time taken:  37.5783770084 0.626306915283\n",
      "Time taken:  37.6039640903 0.626735552152\n",
      "Time taken:  39.1341900826 0.652239716053\n",
      "Time taken:  43.6262271404 0.727106086413\n",
      "Time taken:  44.3673591614 0.739457233747\n",
      "Time taken:  51.5095870495 0.858495767911\n",
      "Time taken:  49.8323729038 0.830541749795\n",
      "Time taken:  47.6226019859 0.793714467684\n",
      "Time taken:  53.2406249046 0.887345834573\n",
      "Time taken:  48.9271330833 0.815452766418\n",
      "Time taken:  47.232542038 0.787211485704\n",
      "Time taken:  51.928486824 0.865475348632\n",
      "Time taken:  33.1530990601 0.552552167575\n",
      "Time taken:  38.8036959171 0.646729063988\n",
      "Time taken:  39.9443559647 0.665744300683\n",
      "Time taken:  42.7595119476 0.712661099434\n",
      "Time taken:  41.6435391903 0.694060436885\n",
      "Time taken:  41.7678191662 0.696132401625\n",
      "Time taken:  43.2335801125 0.720560232798\n",
      "Time taken:  43.1815979481 0.719695850213\n",
      "Time taken:  48.1972231865 0.803287700812\n",
      "Time taken:  48.9980559349 0.816636900107\n",
      "Time taken:  47.2229890823 0.787051816781\n",
      "Time taken:  53.491656065 0.891528117657\n",
      "Time taken:  55.3964800835 0.923277000586\n",
      "Time taken:  54.7570121288 0.912620417277\n",
      "Time taken:  59.2386507988 0.987311681112\n",
      "Time taken:  39.664083004 0.66107048591\n",
      "Time taken:  45.8110890388 0.763520383835\n",
      "Time taken:  46.3637900352 0.772730298837\n",
      "Time taken:  52.0462338924 0.867443267504\n",
      "Time taken:  47.760365963 0.79601016442\n",
      "Time taken:  50.7498428822 0.845832999547\n",
      "Time taken:  47.5333240032 0.792223683993\n",
      "Time taken:  46.9072668552 0.781789946556\n",
      "Time taken:  51.9742510319 0.866238065561\n",
      "Time taken:  56.2519388199 0.937533116341\n",
      "Time taken:  53.4647111893 0.891080117226\n",
      "Time taken:  61.059417963 1.01765766939\n",
      "Time taken:  58.9396789074 0.982328649362\n",
      "Time taken:  56.8993639946 0.948350914319\n",
      "Time taken:  57.2511680126 0.95418741703\n",
      "Time taken:  33.98133111 0.566358717283\n",
      "Time taken:  45.4541509151 0.757569650809\n",
      "Time taken:  44.4325501919 0.740544803937\n",
      "Time taken:  50.5500149727 0.842500785987\n",
      "Time taken:  48.2561941147 0.804272250334\n",
      "Time taken:  52.043418169 0.86739072005\n",
      "Time taken:  44.0169391632 0.733619085948\n",
      "Time taken:  50.4082159996 0.840140219529\n",
      "Time taken:  62.6305170059 1.04387094975\n",
      "Time taken:  58.2648911476 0.97108288606\n",
      "Time taken:  63.1333789825 1.05222851435\n",
      "Time taken:  56.9911808968 0.949856134256\n",
      "Time taken:  61.7445268631 1.02907618284\n",
      "Time taken:  62.3725049496 1.03954238097\n",
      "Time taken:  59.7429521084 0.995743366083\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Baseline MLP\n",
    "#############################################################################################################\n",
    "# Tune #hidden layers and #hidden units (same for each layer)\n",
    "# Dropout fixed\n",
    "\n",
    "epochs = 10000\n",
    "train_batch_size = len(X_train)\n",
    "val_batch_size = len(X_val)\n",
    "test_batch_size = len(X_test)\n",
    "\n",
    "N_runs = 100\n",
    "dropout = 0.5\n",
    "\n",
    "N_hl_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # range of numbers of hidden layers\n",
    "N_hu_range = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80] # range of numbers of units per hidden layer\n",
    "print \"Validation over \", len(N_hl_range) * len(N_hu_range), \"=\", len(N_hl_range), \"x\", len(N_hu_range), \"parameter settings\"\n",
    "vals = np.zeros((len(N_hl_range), len(N_hu_range)))\n",
    "vals_std = np.zeros((len(N_hl_range), len(N_hu_range)))\n",
    "\n",
    "for a, N_hl in enumerate(N_hl_range):\n",
    "    for b, N_hu in enumerate(N_hu_range):\n",
    "        st = time.time()\n",
    "        # Create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(N_hu, activation='relu', kernel_initializer='he_uniform', input_dim=N_features))\n",
    "        model.add(Dropout(dropout))\n",
    "        for i in range(1, N_hl):\n",
    "            model.add(Dense(N_hu, activation='relu', kernel_initializer='he_uniform'))\n",
    "            model.add(Dropout(dropout))\n",
    "        model.add(Dense(N_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "        #print model.summary()\n",
    "        early_stop = EarlyStopping(monitor='val_acc', patience=10, verbose=0) # stop after 10 epochs without improvement in val_acc\n",
    "\n",
    "        vals_actual = []\n",
    "        for i in range(N_runs):\n",
    "            model.fit(X_train, y_train, epochs=epochs, batch_size=train_batch_size, \n",
    "                       validation_data = (X_val, y_val), verbose=0, callbacks=[early_stop])\n",
    "\n",
    "            vals_actual.append( model.evaluate(X_val, y_val, batch_size=val_batch_size, verbose=0)[1] )\n",
    "\n",
    "        vals[a][b] = np.mean(vals_actual)\n",
    "        vals_std[a][b] = np.std(vals_actual)\n",
    "        print \"Time taken: \", time.time()-st, (time.time()-st)/60. \n",
    "# Total ~ 1.5 hod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "# Save the results ! IDs 0,1, are used\n",
    "# TODO save as 1\n",
    "ID = 0 # zeroth trial, smaller # of hidden sizes\n",
    "ID = 1 # first ok trial , more # of hidden sizes\n",
    "\n",
    "if os.path.exists('./../../../Dataset/baseline_' + str(ID) + '.npz'):\n",
    "    raise NameError(\"Set saveID not in use!\")\n",
    "np.savez('./../../../Dataset/baseline_' + str(ID) + '.npz', vals=vals, vals_std=vals_std, \n",
    "         N_hl_range=N_hl_range, N_hu_range=N_hu_range, N_runs=N_runs, dropout=dropout, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
